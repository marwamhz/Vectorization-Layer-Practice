{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35cabca5-21a0-4bb5-a408-fdd583789b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "# Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# run the Enable Deterministic Operations Function\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import optimizers \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = 'pandas')\n",
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "963a0523-27ef-4ac5-9b90-599bbb658331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17718</th>\n",
       "      <td>I could have fancied, while I looked at it, that some eminent landscape painter had built it with his brush.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08973</th>\n",
       "      <td>The lids clenched themselves together as if in a spasm.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05267</th>\n",
       "      <td>Mais il faut agir that is to say, a Frenchman never faints outright.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17513</th>\n",
       "      <td>For an item of news like this, it strikes us it was very coolly received.\"</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00393</th>\n",
       "      <td>He laid a gnarled claw on my shoulder, and it seemed to me that its shaking was not altogether that of mirth.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "...                                                                                                                                                                                                                                          ...   \n",
       "id17718                                                                                                                             I could have fancied, while I looked at it, that some eminent landscape painter had built it with his brush.   \n",
       "id08973                                                                                                                                                                                  The lids clenched themselves together as if in a spasm.   \n",
       "id05267                                                                                                                                                                     Mais il faut agir that is to say, a Frenchman never faints outright.   \n",
       "id17513                                                                                                                                                               For an item of news like this, it strikes us it was very coolly received.\"   \n",
       "id00393                                                                                                                            He laid a gnarled claw on my shoulder, and it seemed to me that its shaking was not altogether that of mirth.   \n",
       "\n",
       "        author  \n",
       "id              \n",
       "id26305    EAP  \n",
       "id17569    HPL  \n",
       "id11008    EAP  \n",
       "id27763    MWS  \n",
       "id12958    HPL  \n",
       "...        ...  \n",
       "id17718    EAP  \n",
       "id08973    EAP  \n",
       "id05267    EAP  \n",
       "id17513    EAP  \n",
       "id00393    HPL  \n",
       "\n",
       "[19579 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/spooky.csv', index_col='id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f127d3d-db88-429f-890c-c9eb5362bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a8535e7-0b1f-4096-b59f-1e7d4c859c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of sequence lengths: 859 with maximum length = 861 and minimum length = 2\n",
      "Average of sequence lengths: 26.73\n"
     ]
    }
   ],
   "source": [
    "# Determine the sequence length of each document in the corpus by using a lambda function to split the text on the spaces\n",
    "seq_length = df['text'].map(lambda x : len(x.split()))\n",
    "# Determine the range of sequence lengths\n",
    "range_of_lengths = max(seq_length) - min(seq_length)\n",
    "print(f\"Range of sequence lengths: {range_of_lengths} with maximum length = {max(seq_length)} and minimum length = {min(seq_length)}\")\n",
    "# Determine the average of sequence lengths\n",
    "average_of_lengths = seq_length.mean()\n",
    "print(\"Average of sequence lengths:\", round(average_of_lengths,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e94991a-f1a6-4339-8ebe-14cb781f1f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76bb9fd1-e93b-4cb8-aded-c3ff0f43132f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    5635\n",
       "HPL    5635\n",
       "MWS    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the RandomUnderSampler to balance the data based on the \"author\" column.\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "df, _ = rus.fit_resample(df, df['author'])\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "766a8557-f093-4317-8537-f2c8b1ef33d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id22483</th>\n",
       "      <td>He then asked me, suddenly, if I had observed any thing peculiar at the scene of the atrocity.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18809</th>\n",
       "      <td>Through the exertions of Beauvais, the matter was industriously hushed up, as far as possible; and several days had elapsed before any public emotion resulted.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16322</th>\n",
       "      <td>The cold was intense, and obliged me to wrap up closely in an overcoat.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13423</th>\n",
       "      <td>I observed that, upon her first elevation of the glass, she had seemed satisfied with a momentary inspection of my person, and was withdrawing the instrument, when, as if struck by a second thought, she resumed it, and so continued to regard me w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09553</th>\n",
       "      <td>There can be no doubt that the consciousness of the rapid increase of my superstition for why should I not so term it?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                              text  \\\n",
       "id                                                                                                                                                                                                                                                                   \n",
       "id22483                                                                                                                                                             He then asked me, suddenly, if I had observed any thing peculiar at the scene of the atrocity.   \n",
       "id18809                                                                                            Through the exertions of Beauvais, the matter was industriously hushed up, as far as possible; and several days had elapsed before any public emotion resulted.   \n",
       "id16322                                                                                                                                                                                    The cold was intense, and obliged me to wrap up closely in an overcoat.   \n",
       "id13423  I observed that, upon her first elevation of the glass, she had seemed satisfied with a momentary inspection of my person, and was withdrawing the instrument, when, as if struck by a second thought, she resumed it, and so continued to regard me w...   \n",
       "id09553                                                                                                                                     There can be no doubt that the consciousness of the rapid increase of my superstition for why should I not so term it?   \n",
       "\n",
       "         author  \n",
       "id               \n",
       "id22483       0  \n",
       "id18809       0  \n",
       "id16322       0  \n",
       "id13423       0  \n",
       "id09553       0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the author strings to integers using the following mapping: EAP: 0, HPL: 1, MWS: 2\n",
    "## Mapping dictionary\n",
    "author_mapping = {'EAP': 0, 'HPL': 1, 'MWS': 2}\n",
    "\n",
    "## Replace author strings with integers based on the mapping\n",
    "df['author'] = df['author'].map(author_mapping)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3de3286d-c04f-4f3b-8b84-3c56a38d3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X as the values from the \"text\" column. Define y as the \"author\" column.\n",
    "\n",
    "X = df['text'].values\n",
    "y = df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32cd8734-761c-4637-a1e2-1a070504a052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a dataset object using Dataset.from_tensor_slices()\n",
    "ds = tf.data.Dataset.from_tensor_slices((X,y))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99778707-d485-4d50-8815-9e228a7163ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - train:\t11833 samples \t(370 batches)\n",
      "    - val:  \t3381 samples \t(106 batches)\n",
      "    - test: \t1691 samples \t(53 batches)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataset\n",
    "ds = ds.shuffle(buffer_size=len(ds),reshuffle_each_iteration=False) \n",
    "\n",
    "# Set the ratio of the train, validation, test split\n",
    "split_train = .7\n",
    "split_val =  .2\n",
    "split_test =  1 -( split_train + split_val )\n",
    "\n",
    "# Calculate the number of samples for training and validation data \n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "n_test_samples = len(ds) -(n_train_samples + n_val_samples)\n",
    "\n",
    "# Set the batch size\n",
    "BATCH_SIZE =32\n",
    "\n",
    "\n",
    "import math\n",
    "# math.ceil will round up\n",
    "# How many batches? \n",
    "n_train_batches = math.ceil(n_train_samples/BATCH_SIZE)\n",
    "n_val_batches = math.ceil(n_val_samples/BATCH_SIZE)\n",
    "n_test_batches = math.ceil(n_test_samples/BATCH_SIZE)\n",
    "\n",
    "print(f\"    - train:\\t{n_train_samples} samples \\t({n_train_batches} batches)\")\n",
    "print(f\"    - val:  \\t{n_val_samples} samples \\t({n_val_batches} batches)\")\n",
    "print(f\"    - test: \\t{n_test_samples} samples \\t({n_test_batches} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e4a6531-d389-49a0-8db8-6d9ba3dfc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use take and skip to define each set\n",
    "train_ds = ds.take(n_train_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skip over the training batches and take the validation batches\n",
    "val_ds = ds.skip(n_train_samples).take(n_val_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skipver the train and validation batches, the remaining are the test batches\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8cc76763-2948-499c-b4bb-c825ee1b588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text Vectorization layer\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6465bab-fbff-48cb-89e0-0d2b15032460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the text from the training dataset using a lambda function\n",
    "ds_texts = train_ds.map(lambda x ,y : x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "48133f50-9666-47dc-a673-c924404804b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (adapt) the vectorization layer on the text data\n",
    "sequence_vectorizer.adapt(ds_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64293748-b7e4-4a53-b7a2-8b280f7e88df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20976"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get vocabulary size\n",
    "sequence_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c438a8e6-7796-4f0f-a101-2c8c98109b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'the',\n",
       " 3: 'of',\n",
       " 4: 'and',\n",
       " 5: 'to',\n",
       " 6: 'i',\n",
       " 7: 'a',\n",
       " 8: 'in',\n",
       " 9: 'was',\n",
       " 10: 'that',\n",
       " 11: 'my',\n",
       " 12: 'it',\n",
       " 13: 'he',\n",
       " 14: 'had',\n",
       " 15: 'with',\n",
       " 16: 'his',\n",
       " 17: 'as',\n",
       " 18: 'for',\n",
       " 19: 'but',\n",
       " 20: 'which',\n",
       " 21: 'not',\n",
       " 22: 'me',\n",
       " 23: 'at',\n",
       " 24: 'from',\n",
       " 25: 'by',\n",
       " 26: 'on',\n",
       " 27: 'this',\n",
       " 28: 'is',\n",
       " 29: 'her',\n",
       " 30: 'be',\n",
       " 31: 'were',\n",
       " 32: 'have',\n",
       " 33: 'you',\n",
       " 34: 'all',\n",
       " 35: 'an',\n",
       " 36: 'we',\n",
       " 37: 'or',\n",
       " 38: 'no',\n",
       " 39: 'when',\n",
       " 40: 'him',\n",
       " 41: 'one',\n",
       " 42: 'so',\n",
       " 43: 'they',\n",
       " 44: 'been',\n",
       " 45: 'could',\n",
       " 46: 'would',\n",
       " 47: 'she',\n",
       " 48: 'there',\n",
       " 49: 'upon',\n",
       " 50: 'more',\n",
       " 51: 'its',\n",
       " 52: 'their',\n",
       " 53: 'now',\n",
       " 54: 'what',\n",
       " 55: 'some',\n",
       " 56: 'our',\n",
       " 57: 'into',\n",
       " 58: 'if',\n",
       " 59: 'them',\n",
       " 60: 'who',\n",
       " 61: 'are',\n",
       " 62: 'will',\n",
       " 63: 'than',\n",
       " 64: 'then',\n",
       " 65: 'only',\n",
       " 66: 'very',\n",
       " 67: 'up',\n",
       " 68: 'before',\n",
       " 69: 'man',\n",
       " 70: 'about',\n",
       " 71: 'even',\n",
       " 72: 'these',\n",
       " 73: 'out',\n",
       " 74: 'yet',\n",
       " 75: 'your',\n",
       " 76: 'time',\n",
       " 77: 'did',\n",
       " 78: 'any',\n",
       " 79: 'old',\n",
       " 80: 'said',\n",
       " 81: 'might',\n",
       " 82: 'like',\n",
       " 83: 'after',\n",
       " 84: 'over',\n",
       " 85: 'first',\n",
       " 86: 'night',\n",
       " 87: 'life',\n",
       " 88: 'through',\n",
       " 89: 'eyes',\n",
       " 90: 'us',\n",
       " 91: 'must',\n",
       " 92: 'do',\n",
       " 93: 'never',\n",
       " 94: 'most',\n",
       " 95: 'seemed',\n",
       " 96: 'should',\n",
       " 97: 'other',\n",
       " 98: 'found',\n",
       " 99: 'while',\n",
       " 100: 'made',\n",
       " 101: 'such',\n",
       " 102: 'saw',\n",
       " 103: 'great',\n",
       " 104: 'those',\n",
       " 105: 'still',\n",
       " 106: 'day',\n",
       " 107: 'where',\n",
       " 108: 'little',\n",
       " 109: 'every',\n",
       " 110: 'long',\n",
       " 111: 'again',\n",
       " 112: 'myself',\n",
       " 113: 'many',\n",
       " 114: 'down',\n",
       " 115: 'well',\n",
       " 116: 'has',\n",
       " 117: 'came',\n",
       " 118: 'how',\n",
       " 119: 'own',\n",
       " 120: 'much',\n",
       " 121: 'once',\n",
       " 122: 'can',\n",
       " 123: 'may',\n",
       " 124: 'two',\n",
       " 125: 'thought',\n",
       " 126: 'whose',\n",
       " 127: 'ever',\n",
       " 128: 'being',\n",
       " 129: 'death',\n",
       " 130: 'am',\n",
       " 131: 'things',\n",
       " 132: 'see',\n",
       " 133: 'men',\n",
       " 134: 'heard',\n",
       " 135: 'thus',\n",
       " 136: 'heart',\n",
       " 137: 'mind',\n",
       " 138: 'far',\n",
       " 139: 'too',\n",
       " 140: 'thing',\n",
       " 141: 'say',\n",
       " 142: 'know',\n",
       " 143: 'without',\n",
       " 144: 'left',\n",
       " 145: 'house',\n",
       " 146: 'shall',\n",
       " 147: 'though',\n",
       " 148: 'felt',\n",
       " 149: 'last',\n",
       " 150: 'here',\n",
       " 151: 'love',\n",
       " 152: 'come',\n",
       " 153: 'place',\n",
       " 154: 'away',\n",
       " 155: 'himself',\n",
       " 156: 'years',\n",
       " 157: 'became',\n",
       " 158: 'light',\n",
       " 159: 'few',\n",
       " 160: 'world',\n",
       " 161: 'however',\n",
       " 162: 'earth',\n",
       " 163: 'each',\n",
       " 164: 'nor',\n",
       " 165: 'indeed',\n",
       " 166: 'seen',\n",
       " 167: 'way',\n",
       " 168: 'room',\n",
       " 169: 'head',\n",
       " 170: 'words',\n",
       " 171: 'knew',\n",
       " 172: 'back',\n",
       " 173: 'door',\n",
       " 174: 'strange',\n",
       " 175: 'new',\n",
       " 176: 'whole',\n",
       " 177: 'hand',\n",
       " 178: 'human',\n",
       " 179: 'voice',\n",
       " 180: 'under',\n",
       " 181: 'same',\n",
       " 182: 'half',\n",
       " 183: 'fear',\n",
       " 184: 'let',\n",
       " 185: 'beyond',\n",
       " 186: 'nothing',\n",
       " 187: 'make',\n",
       " 188: 'having',\n",
       " 189: 'friend',\n",
       " 190: 'three',\n",
       " 191: 'soon',\n",
       " 192: 'raymond',\n",
       " 193: 'father',\n",
       " 194: 'off',\n",
       " 195: 'good',\n",
       " 196: 'during',\n",
       " 197: 'among',\n",
       " 198: 'length',\n",
       " 199: 'part',\n",
       " 200: 'moment',\n",
       " 201: 'within',\n",
       " 202: 'nature',\n",
       " 203: 'less',\n",
       " 204: 'alone',\n",
       " 205: 'looked',\n",
       " 206: 'since',\n",
       " 207: 'almost',\n",
       " 208: 'small',\n",
       " 209: 'near',\n",
       " 210: 'gave',\n",
       " 211: 'around',\n",
       " 212: 'something',\n",
       " 213: 'sea',\n",
       " 214: 'another',\n",
       " 215: 'told',\n",
       " 216: 'face',\n",
       " 217: 'city',\n",
       " 218: 'appeared',\n",
       " 219: 'went',\n",
       " 220: 'passed',\n",
       " 221: 'air',\n",
       " 222: 'young',\n",
       " 223: 'whom',\n",
       " 224: 'find',\n",
       " 225: 'dark',\n",
       " 226: 'took',\n",
       " 227: 'soul',\n",
       " 228: 'certain',\n",
       " 229: 'although',\n",
       " 230: 'full',\n",
       " 231: 'tell',\n",
       " 232: 'high',\n",
       " 233: 'days',\n",
       " 234: 'also',\n",
       " 235: 'think',\n",
       " 236: 'horror',\n",
       " 237: 'take',\n",
       " 238: 'began',\n",
       " 239: 'above',\n",
       " 240: 'just',\n",
       " 241: 'end',\n",
       " 242: 'body',\n",
       " 243: 'lay',\n",
       " 244: 'dead',\n",
       " 245: 'course',\n",
       " 246: 'black',\n",
       " 247: 'why',\n",
       " 248: 'hope',\n",
       " 249: 'form',\n",
       " 250: 'street',\n",
       " 251: 'o',\n",
       " 252: 'go',\n",
       " 253: 'turned',\n",
       " 254: 'kind',\n",
       " 255: 'towards',\n",
       " 256: 'itself',\n",
       " 257: 'open',\n",
       " 258: 'spirit',\n",
       " 259: 'cannot',\n",
       " 260: 'mr',\n",
       " 261: 'least',\n",
       " 262: 'because',\n",
       " 263: 'water',\n",
       " 264: 'scene',\n",
       " 265: 'point',\n",
       " 266: 'often',\n",
       " 267: 'between',\n",
       " 268: 'sometimes',\n",
       " 269: 'look',\n",
       " 270: 'lost',\n",
       " 271: 'known',\n",
       " 272: 'always',\n",
       " 273: 'until',\n",
       " 274: 'name',\n",
       " 275: 'hours',\n",
       " 276: 'deep',\n",
       " 277: 'ancient',\n",
       " 278: 'feet',\n",
       " 279: 'taken',\n",
       " 280: 'return',\n",
       " 281: 'perhaps',\n",
       " 282: 'against',\n",
       " 283: 'morning',\n",
       " 284: 'white',\n",
       " 285: 'rather',\n",
       " 286: 'hands',\n",
       " 287: 'dream',\n",
       " 288: 'sun',\n",
       " 289: 'present',\n",
       " 290: 'home',\n",
       " 291: 'eye',\n",
       " 292: 'town',\n",
       " 293: 'spoke',\n",
       " 294: 'idea',\n",
       " 295: 'brought',\n",
       " 296: 'both',\n",
       " 297: 'power',\n",
       " 298: 'called',\n",
       " 299: 'stood',\n",
       " 300: 'sight',\n",
       " 301: 'side',\n",
       " 302: 'right',\n",
       " 303: 'put',\n",
       " 304: 'people',\n",
       " 305: 'moon',\n",
       " 306: 'fell',\n",
       " 307: 'thousand',\n",
       " 308: 'speak',\n",
       " 309: 'poor',\n",
       " 310: 'perdita',\n",
       " 311: 'others',\n",
       " 312: 'country',\n",
       " 313: 'object',\n",
       " 314: 'matter',\n",
       " 315: 'terrible',\n",
       " 316: 'floor',\n",
       " 317: 'done',\n",
       " 318: 'change',\n",
       " 319: 'beauty',\n",
       " 320: 'times',\n",
       " 321: 'several',\n",
       " 322: 'person',\n",
       " 323: 'nearly',\n",
       " 324: 'sound',\n",
       " 325: 'grew',\n",
       " 326: 'feel',\n",
       " 327: 'truth',\n",
       " 328: 'means',\n",
       " 329: 'manner',\n",
       " 330: 'give',\n",
       " 331: 'evil',\n",
       " 332: 'entered',\n",
       " 333: 'dreams',\n",
       " 334: 'continued',\n",
       " 335: 'believe',\n",
       " 336: 'west',\n",
       " 337: 'set',\n",
       " 338: 'better',\n",
       " 339: 'become',\n",
       " 340: 'till',\n",
       " 341: 'quite',\n",
       " 342: 'hour',\n",
       " 343: 'true',\n",
       " 344: 'themselves',\n",
       " 345: 'stone',\n",
       " 346: 'sleep',\n",
       " 347: 'read',\n",
       " 348: 'past',\n",
       " 349: 'gone',\n",
       " 350: 'work',\n",
       " 351: 'tears',\n",
       " 352: 'suddenly',\n",
       " 353: 'trees',\n",
       " 354: 'state',\n",
       " 355: 'happy',\n",
       " 356: 'family',\n",
       " 357: 'fact',\n",
       " 358: 'despair',\n",
       " 359: 'case',\n",
       " 360: 'wild',\n",
       " 361: 'second',\n",
       " 362: 'general',\n",
       " 363: 'longer',\n",
       " 364: 'dear',\n",
       " 365: 'possible',\n",
       " 366: 'none',\n",
       " 367: 'adrian',\n",
       " 368: 'thoughts',\n",
       " 369: 'doubt',\n",
       " 370: 'died',\n",
       " 371: 'wonder',\n",
       " 372: 'led',\n",
       " 373: 'happiness',\n",
       " 374: 'de',\n",
       " 375: 'close',\n",
       " 376: 'window',\n",
       " 377: 'walls',\n",
       " 378: 'next',\n",
       " 379: 'ground',\n",
       " 380: 'gentle',\n",
       " 381: 'wish',\n",
       " 382: 'secret',\n",
       " 383: 'remained',\n",
       " 384: 'countenance',\n",
       " 385: 'sense',\n",
       " 386: 'reason',\n",
       " 387: 'idris',\n",
       " 388: 'child',\n",
       " 389: 'already',\n",
       " 390: 'wind',\n",
       " 391: 'god',\n",
       " 392: 'existence',\n",
       " 393: 'evening',\n",
       " 394: 'enough',\n",
       " 395: 'blood',\n",
       " 396: 'word',\n",
       " 397: 'together',\n",
       " 398: 'mother',\n",
       " 399: 'low',\n",
       " 400: 'friends',\n",
       " 401: 'feelings',\n",
       " 402: 'beneath',\n",
       " 403: 'age',\n",
       " 404: 'unknown',\n",
       " 405: 'rest',\n",
       " 406: 'replied',\n",
       " 407: 'large',\n",
       " 408: 'get',\n",
       " 409: 'five',\n",
       " 410: 'character',\n",
       " 411: 'attention',\n",
       " 412: 'appearance',\n",
       " 413: 'wall',\n",
       " 414: 'space',\n",
       " 415: 'sky',\n",
       " 416: 'oh',\n",
       " 417: 'lips',\n",
       " 418: 'hideous',\n",
       " 419: 'feeling',\n",
       " 420: 'england',\n",
       " 421: 'either',\n",
       " 422: 'best',\n",
       " 423: 'behind',\n",
       " 424: 'windows',\n",
       " 425: 'looking',\n",
       " 426: 'late',\n",
       " 427: 'land',\n",
       " 428: 'immediately',\n",
       " 429: 'sat',\n",
       " 430: 'held',\n",
       " 431: 'fellow',\n",
       " 432: 'children',\n",
       " 433: 'therefore',\n",
       " 434: 'period',\n",
       " 435: 'hear',\n",
       " 436: 'given',\n",
       " 437: 'filled',\n",
       " 438: 'along',\n",
       " 439: 'account',\n",
       " 440: 'spot',\n",
       " 441: 'river',\n",
       " 442: 'misery',\n",
       " 443: 'living',\n",
       " 444: 'chamber',\n",
       " 445: 'toward',\n",
       " 446: 'joy',\n",
       " 447: 'imagination',\n",
       " 448: 'short',\n",
       " 449: 'reached',\n",
       " 450: 'cold',\n",
       " 451: 'returned',\n",
       " 452: 'natural',\n",
       " 453: 'mad',\n",
       " 454: 'loved',\n",
       " 455: 'interest',\n",
       " 456: 'followed',\n",
       " 457: 'view',\n",
       " 458: 'sure',\n",
       " 459: 'steps',\n",
       " 460: 'leave',\n",
       " 461: 'knowledge',\n",
       " 462: 'four',\n",
       " 463: 'care',\n",
       " 464: 'vast',\n",
       " 465: 'tried',\n",
       " 466: 'sir',\n",
       " 467: 'neither',\n",
       " 468: 'herself',\n",
       " 469: 'fire',\n",
       " 470: 'early',\n",
       " 471: 'cast',\n",
       " 472: 'arms',\n",
       " 473: 'affection',\n",
       " 474: 'terror',\n",
       " 475: 'question',\n",
       " 476: 'greater',\n",
       " 477: 'gods',\n",
       " 478: 'escape',\n",
       " 479: 'distance',\n",
       " 480: 'youth',\n",
       " 481: 'silence',\n",
       " 482: 'observed',\n",
       " 483: 'north',\n",
       " 484: 'months',\n",
       " 485: 'latter',\n",
       " 486: 'kept',\n",
       " 487: 'bed',\n",
       " 488: 'table',\n",
       " 489: 'memory',\n",
       " 490: 'live',\n",
       " 491: 'letter',\n",
       " 492: 'ill',\n",
       " 493: 'discovered',\n",
       " 494: 'die',\n",
       " 495: 'year',\n",
       " 496: 'self',\n",
       " 497: 'necessary',\n",
       " 498: 'mine',\n",
       " 499: 'hill',\n",
       " 500: 'darkness',\n",
       " 501: 'common',\n",
       " 502: 'coming',\n",
       " 503: 'circumstances',\n",
       " 504: 'caused',\n",
       " 505: 'call',\n",
       " 506: 'beautiful',\n",
       " 507: 'arm',\n",
       " 508: 'across',\n",
       " 509: 'subject',\n",
       " 510: 'really',\n",
       " 511: 'purpose',\n",
       " 512: 'possessed',\n",
       " 513: 'merely',\n",
       " 514: 'heavy',\n",
       " 515: 'heaven',\n",
       " 516: 'green',\n",
       " 517: 'forth',\n",
       " 518: 'dr',\n",
       " 519: 'cause',\n",
       " 520: 'born',\n",
       " 521: 'use',\n",
       " 522: 'thy',\n",
       " 523: 'thou',\n",
       " 524: 'sought',\n",
       " 525: 'six',\n",
       " 526: 'remember',\n",
       " 527: 'received',\n",
       " 528: 'grief',\n",
       " 529: 'various',\n",
       " 530: 'threw',\n",
       " 531: 'save',\n",
       " 532: 'portion',\n",
       " 533: 'pleasure',\n",
       " 534: 'met',\n",
       " 535: 'later',\n",
       " 536: 'excited',\n",
       " 537: 'woman',\n",
       " 538: 'strength',\n",
       " 539: 'scarcely',\n",
       " 540: 'mere',\n",
       " 541: 'line',\n",
       " 542: 'houses',\n",
       " 543: 'formed',\n",
       " 544: 'finally',\n",
       " 545: 'drew',\n",
       " 546: 'beheld',\n",
       " 547: 'ye',\n",
       " 548: 'pain',\n",
       " 549: 'opened',\n",
       " 550: 'native',\n",
       " 551: 'entirely',\n",
       " 552: 'delight',\n",
       " 553: 'cottage',\n",
       " 554: 'wide',\n",
       " 555: 'valley',\n",
       " 556: 'somewhat',\n",
       " 557: 'peculiar',\n",
       " 558: 'instant',\n",
       " 559: 'fancy',\n",
       " 560: 'usual',\n",
       " 561: 'tale',\n",
       " 562: 'streets',\n",
       " 563: 'red',\n",
       " 564: 'outside',\n",
       " 565: 'london',\n",
       " 566: 'lady',\n",
       " 567: 'especially',\n",
       " 568: 'distant',\n",
       " 569: 'degree',\n",
       " 570: 'corpse',\n",
       " 571: 'box',\n",
       " 572: 'wished',\n",
       " 573: 'visible',\n",
       " 574: 'sounds',\n",
       " 575: 'sister',\n",
       " 576: 'rose',\n",
       " 577: 'road',\n",
       " 578: 'got',\n",
       " 579: 'cut',\n",
       " 580: 'calm',\n",
       " 581: 'broken',\n",
       " 582: 'below',\n",
       " 583: 'visit',\n",
       " 584: 'twenty',\n",
       " 585: 'turn',\n",
       " 586: 'ten',\n",
       " 587: 'silent',\n",
       " 588: 'shadow',\n",
       " 589: 'placed',\n",
       " 590: 'hold',\n",
       " 591: 'does',\n",
       " 592: 'book',\n",
       " 593: 'blue',\n",
       " 594: 'asked',\n",
       " 595: 'arrived',\n",
       " 596: 'arose',\n",
       " 597: 'uncle',\n",
       " 598: 'simple',\n",
       " 599: 'round',\n",
       " 600: 'resolved',\n",
       " 601: 'madness',\n",
       " 602: 'lovely',\n",
       " 603: 'lived',\n",
       " 604: 'impossible',\n",
       " 605: 'hills',\n",
       " 606: 'grave',\n",
       " 607: 'faint',\n",
       " 608: 'expression',\n",
       " 609: 'difficulty',\n",
       " 610: 'curious',\n",
       " 611: 'creatures',\n",
       " 612: 'companion',\n",
       " 613: 'closed',\n",
       " 614: 'castle',\n",
       " 615: 'altogether',\n",
       " 616: 'top',\n",
       " 617: 'sweet',\n",
       " 618: 'south',\n",
       " 619: 'horrible',\n",
       " 620: 'fate',\n",
       " 621: 'bring',\n",
       " 622: 'boat',\n",
       " 623: 'spent',\n",
       " 624: 'presence',\n",
       " 625: 'paper',\n",
       " 626: 'mountain',\n",
       " 627: 'keep',\n",
       " 628: 'ice',\n",
       " 629: 'hair',\n",
       " 630: 'east',\n",
       " 631: 'clear',\n",
       " 632: 'books',\n",
       " 633: 'beloved',\n",
       " 634: 'yes',\n",
       " 635: 'whether',\n",
       " 636: 'son',\n",
       " 637: 'slight',\n",
       " 638: 'real',\n",
       " 639: 'odd',\n",
       " 640: 'free',\n",
       " 641: 'force',\n",
       " 642: 'else',\n",
       " 643: 'deserted',\n",
       " 644: 'dared',\n",
       " 645: 'wife',\n",
       " 646: 'want',\n",
       " 647: 'sorrow',\n",
       " 648: 'narrow',\n",
       " 649: 'hardly',\n",
       " 650: 'fully',\n",
       " 651: 'figure',\n",
       " 652: 'events',\n",
       " 653: 'easily',\n",
       " 654: 'creature',\n",
       " 655: 'bore',\n",
       " 656: 'atmosphere',\n",
       " 657: 'ago',\n",
       " 658: 'talked',\n",
       " 659: 'proceeded',\n",
       " 660: 'position',\n",
       " 661: 'party',\n",
       " 662: 'order',\n",
       " 663: 'ocean',\n",
       " 664: 'occurred',\n",
       " 665: 'music',\n",
       " 666: 'mountains',\n",
       " 667: 'marble',\n",
       " 668: 'lord',\n",
       " 669: 'future',\n",
       " 670: 'english',\n",
       " 671: 'effect',\n",
       " 672: 'danger',\n",
       " 673: 'cried',\n",
       " 674: 'changed',\n",
       " 675: 'anything',\n",
       " 676: 'tomb',\n",
       " 677: 'stars',\n",
       " 678: 'singular',\n",
       " 679: 'single',\n",
       " 680: 'shore',\n",
       " 681: 'seized',\n",
       " 682: 'says',\n",
       " 683: 'reality',\n",
       " 684: 'public',\n",
       " 685: 'pale',\n",
       " 686: 'minutes',\n",
       " 687: 'hard',\n",
       " 688: 'grey',\n",
       " 689: 'going',\n",
       " 690: 'frightful',\n",
       " 691: 'fresh',\n",
       " 692: 'forest',\n",
       " 693: 'fallen',\n",
       " 694: 'expected',\n",
       " 695: 'direction',\n",
       " 696: 'courage',\n",
       " 697: 'brain',\n",
       " 698: 'apparently',\n",
       " 699: 'vain',\n",
       " 700: 'thrown',\n",
       " 701: 'thee',\n",
       " 702: 'struck',\n",
       " 703: 'step',\n",
       " 704: 'society',\n",
       " 705: 'progress',\n",
       " 706: 'ones',\n",
       " 707: 'miles',\n",
       " 708: 'hopes',\n",
       " 709: 'forgotten',\n",
       " 710: 'foot',\n",
       " 711: 'elizabeth',\n",
       " 712: 'different',\n",
       " 713: 'condition',\n",
       " 714: 'able',\n",
       " 715: 'windsor',\n",
       " 716: 'utterly',\n",
       " 717: 'story',\n",
       " 718: 'st',\n",
       " 719: 'passion',\n",
       " 720: 'moved',\n",
       " 721: 'influence',\n",
       " 722: 'hidden',\n",
       " 723: 'golden',\n",
       " 724: 'gilman',\n",
       " 725: 'former',\n",
       " 726: 'fears',\n",
       " 727: 'dare',\n",
       " 728: 'boy',\n",
       " 729: 'beings',\n",
       " 730: 'approached',\n",
       " 731: 'absence',\n",
       " 732: 'whilst',\n",
       " 733: 'third',\n",
       " 734: 'strong',\n",
       " 735: 'plague',\n",
       " 736: 'persons',\n",
       " 737: 'perceived',\n",
       " 738: 'passage',\n",
       " 739: 'objects',\n",
       " 740: 'motion',\n",
       " 741: 'miserable',\n",
       " 742: 'mean',\n",
       " 743: 'making',\n",
       " 744: 'journey',\n",
       " 745: 'girl',\n",
       " 746: 'frame',\n",
       " 747: 'fine',\n",
       " 748: 'describe',\n",
       " 749: 'art',\n",
       " 750: 'watched',\n",
       " 751: 'walked',\n",
       " 752: 'tree',\n",
       " 753: 'task',\n",
       " 754: 'taking',\n",
       " 755: 'storm',\n",
       " 756: 'sort',\n",
       " 757: 'ship',\n",
       " 758: 'seek',\n",
       " 759: 'rise',\n",
       " 760: 'remote',\n",
       " 761: 'rain',\n",
       " 762: 'quickly',\n",
       " 763: 'path',\n",
       " 764: 'pass',\n",
       " 765: 'midnight',\n",
       " 766: 'main',\n",
       " 767: 'health',\n",
       " 768: 'fall',\n",
       " 769: 'exceedingly',\n",
       " 770: 'evidently',\n",
       " 771: 'curiosity',\n",
       " 772: 'besides',\n",
       " 773: 'alive',\n",
       " 774: 'action',\n",
       " 775: 'act',\n",
       " 776: 'wood',\n",
       " 777: 'winter',\n",
       " 778: 'understand',\n",
       " 779: 'summer',\n",
       " 780: 'sudden',\n",
       " 781: 'rendered',\n",
       " 782: 'places',\n",
       " 783: 'peace',\n",
       " 784: 'monstrous',\n",
       " 785: 'listened',\n",
       " 786: 'immediate',\n",
       " 787: 'hung',\n",
       " 788: 'height',\n",
       " 789: 'gold',\n",
       " 790: 'fearful',\n",
       " 791: 'faces',\n",
       " 792: 'dont',\n",
       " 793: 'conversation',\n",
       " 794: 'carried',\n",
       " 795: 'arkham',\n",
       " 796: 'vague',\n",
       " 797: 'surface',\n",
       " 798: 'smile',\n",
       " 799: 'slowly',\n",
       " 800: 'situation',\n",
       " 801: 'remain',\n",
       " 802: 'reach',\n",
       " 803: 'ran',\n",
       " 804: 'queer',\n",
       " 805: 'need',\n",
       " 806: 'mouth',\n",
       " 807: 'mighty',\n",
       " 808: 'mentioned',\n",
       " 809: 'madame',\n",
       " 810: 'king',\n",
       " 811: 'hundred',\n",
       " 812: 'help',\n",
       " 813: 'extreme',\n",
       " 814: 'extent',\n",
       " 815: 'ears',\n",
       " 816: 'disease',\n",
       " 817: 'daughter',\n",
       " 818: 'corner',\n",
       " 819: 'company',\n",
       " 820: 'certainly',\n",
       " 821: 'behold',\n",
       " 822: 'balloon',\n",
       " 823: 'appear',\n",
       " 824: 'yourself',\n",
       " 825: 'village',\n",
       " 826: 'thin',\n",
       " 827: 'talk',\n",
       " 828: 'supposed',\n",
       " 829: 'shewed',\n",
       " 830: 'senses',\n",
       " 831: 'seems',\n",
       " 832: 'promise',\n",
       " 833: 'machine',\n",
       " 834: 'listen',\n",
       " 835: 'language',\n",
       " 836: 'glass',\n",
       " 837: 'features',\n",
       " 838: 'fathers',\n",
       " 839: 'familiar',\n",
       " 840: 'desire',\n",
       " 841: 'car',\n",
       " 842: 'business',\n",
       " 843: 'alas',\n",
       " 844: 'weight',\n",
       " 845: 'violent',\n",
       " 846: 'sympathy',\n",
       " 847: 'started',\n",
       " 848: 'sinister',\n",
       " 849: 'science',\n",
       " 850: 'result',\n",
       " 851: 'quiet',\n",
       " 852: 'prepared',\n",
       " 853: 'paused',\n",
       " 854: 'nose',\n",
       " 855: 'noble',\n",
       " 856: 'leaving',\n",
       " 857: 'innsmouth',\n",
       " 858: 'image',\n",
       " 859: 'glory',\n",
       " 860: 'forever',\n",
       " 861: 'determined',\n",
       " 862: 'clouds',\n",
       " 863: 'building',\n",
       " 864: 'attempt',\n",
       " 865: 'agony',\n",
       " 866: 'visited',\n",
       " 867: 'thick',\n",
       " 868: 'sufficient',\n",
       " 869: 'suffered',\n",
       " 870: 'success',\n",
       " 871: 'succeeded',\n",
       " 872: 'spring',\n",
       " 873: 'spread',\n",
       " 874: 'solitude',\n",
       " 875: 'sole',\n",
       " 876: 'reflection',\n",
       " 877: 'pocket',\n",
       " 878: 'occupied',\n",
       " 879: 'nervous',\n",
       " 880: 'hall',\n",
       " 881: 'forms',\n",
       " 882: 'follow',\n",
       " 883: 'flowers',\n",
       " 884: 'fever',\n",
       " 885: 'except',\n",
       " 886: 'dupin',\n",
       " 887: 'despite',\n",
       " 888: 'considered',\n",
       " 889: 'conduct',\n",
       " 890: 'big',\n",
       " 891: 'apparent',\n",
       " 892: 'woods',\n",
       " 893: 'waters',\n",
       " 894: 'utter',\n",
       " 895: 'trace',\n",
       " 896: 'roof',\n",
       " 897: 'relief',\n",
       " 898: 'powers',\n",
       " 899: 'ordinary',\n",
       " 900: 'notice',\n",
       " 901: 'melancholy',\n",
       " 902: 'marked',\n",
       " 903: 'm',\n",
       " 904: 'island',\n",
       " 905: 'ideas',\n",
       " 906: 'forced',\n",
       " 907: 'feared',\n",
       " 908: 'fashion',\n",
       " 909: 'expressed',\n",
       " 910: 'experienced',\n",
       " 911: 'crowd',\n",
       " 912: 'covered',\n",
       " 913: 'concerning',\n",
       " 914: 'century',\n",
       " 915: 'carefully',\n",
       " 916: 'bodies',\n",
       " 917: 'apartment',\n",
       " 918: 'aid',\n",
       " 919: 'accursed',\n",
       " 920: 'watch',\n",
       " 921: 'used',\n",
       " 922: 'unable',\n",
       " 923: 'temple',\n",
       " 924: 'tall',\n",
       " 925: 'tales',\n",
       " 926: 'study',\n",
       " 927: 'soft',\n",
       " 928: 'rock',\n",
       " 929: 'remembered',\n",
       " 930: 'recall',\n",
       " 931: 'perceive',\n",
       " 932: 'original',\n",
       " 933: 'mystery',\n",
       " 934: 'minute',\n",
       " 935: 'mental',\n",
       " 936: 'meet',\n",
       " 937: 'limbs',\n",
       " 938: 'learned',\n",
       " 939: 'lake',\n",
       " 940: 'key',\n",
       " 941: 'heavens',\n",
       " 942: 'forward',\n",
       " 943: 'enter',\n",
       " 944: 'enemy',\n",
       " 945: 'discovery',\n",
       " 946: 'destruction',\n",
       " 947: 'bitter',\n",
       " 948: 'bent',\n",
       " 949: 'anxiety',\n",
       " 950: 'answer',\n",
       " 951: 'amidst',\n",
       " 952: 'wholly',\n",
       " 953: 'week',\n",
       " 954: 'vision',\n",
       " 955: 'stranger',\n",
       " 956: 'spirits',\n",
       " 957: 'shut',\n",
       " 958: 'seem',\n",
       " 959: 'regard',\n",
       " 960: 'professor',\n",
       " 961: 'probably',\n",
       " 962: 'presented',\n",
       " 963: 'noticed',\n",
       " 964: 'material',\n",
       " 965: 'impression',\n",
       " 966: 'haunted',\n",
       " 967: 'greek',\n",
       " 968: 'greatest',\n",
       " 969: 'glance',\n",
       " 970: 'ghastly',\n",
       " 971: 'gentleman',\n",
       " 972: 'fled',\n",
       " 973: 'farewell',\n",
       " 974: 'fair',\n",
       " 975: 'dying',\n",
       " 976: 'dwelt',\n",
       " 977: 'duty',\n",
       " 978: 'departure',\n",
       " 979: 'degrees',\n",
       " 980: 'brother',\n",
       " 981: 'beside',\n",
       " 982: 'bear',\n",
       " 983: 'aside',\n",
       " 984: 'aout',\n",
       " 985: 'weak',\n",
       " 986: 'walk',\n",
       " 987: 'try',\n",
       " 988: 'sufficiently',\n",
       " 989: 'servant',\n",
       " 990: 'sent',\n",
       " 991: 'satisfied',\n",
       " 992: 'respect',\n",
       " 993: 'region',\n",
       " 994: 'produced',\n",
       " 995: 'plain',\n",
       " 996: 'permitted',\n",
       " 997: 'palace',\n",
       " 998: 'painful',\n",
       " 999: 'oclock',\n",
       " ...}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a look-up dictionary that will allow you to look up the word associated with an integer. \n",
    "\n",
    "vocab = sequence_vectorizer.get_vocabulary()\n",
    "int_to_str = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "int_to_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab45ac11-7ccd-4882-a502-982b4b93348b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'occasion'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What word is associated with integer 1000?\n",
    "int_to_str[1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4652fbcc-2478-4db7-a2fe-3ae51f522d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
       "array([[ 6345,     1,    28,    35,  6996, 13401,    18,     1,  6345,\n",
       "           57,     7,     1,    10,   833,  3862, 16160,   122,   521,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0]], dtype=int64)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the vectorized result of the sample text: \"Text Vectorization is an essential tool for converting text into a format that machine learning models can use.\"\n",
    "sequence = sequence_vectorizer([\"Text Vectorization is an essential tool for converting text into a format that machine learning models can use.\"])\n",
    "sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
